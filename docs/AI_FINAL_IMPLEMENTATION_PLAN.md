# AI Bitcoin Price Prediction - FINAL ACCURATE PLAN

**Date:** November 28, 2025  
**Current BTC Price:** ~$91,195 USD  
**Status:** Ready to implement after infrastructure review

---

## ‚úÖ ACTUAL SITUATION (Verified)

### Database Status: GOOD ‚úÖ
- **Location:** `/backend/data/prices.sqlite` (correct path, working!)
- **Real Price Data:** 74 rows with accurate prices
  - Source `api`: 62 rows (range: $94,187 - $114,531)
  - Source `coingecko`: 12 rows (range: $91,747 - $91,896)
- **Hashrate Data:** 361 rows (sufficient for features)
- **Difficulty Data:** 361 rows (sufficient for features)

### What's Working:
- ‚úÖ Database connection and structure
- ‚úÖ CoinGecko API integration (tested: returns $91,195)
- ‚úÖ Existing backfill script works correctly
- ‚úÖ Hashrate/Difficulty pollers running

### What's Missing:
- ‚ùå Only 74 price records ‚Üí Need 8,000+ for training
- ‚ùå No automatic price polling service
- ‚ùå Price data is sparse (not hourly)

---

## üéØ SIMPLIFIED 3-WEEK PLAN

### Week 1: Data Collection (PRIORITY)

#### Day 1-2: Backfill Historical Data
```bash
# Run this to get 2 years of hourly BTC prices
cd backend
node scripts/backfill-prices.js BTC 730

# This will add ~17,520 hourly price records
```

**Expected Result:** Database grows from 74 ‚Üí 17,500+ rows

#### Day 3: Create Price Polling Service

**File:** `backend/app/services/pricePoller.js`

```javascript
import { insertPrice } from '../db/pricesDb.js';

let pollingInterval = null;
const POLL_INTERVAL = 5 * 60 * 1000; // 5 minutes

export function startPricePolling() {
  if (pollingInterval) return;
  
  console.log('üîÑ Starting BTC price polling (every 5min)...');
  pollPrice(); // immediate
  pollingInterval = setInterval(pollPrice, POLL_INTERVAL);
}

async function pollPrice() {
  try {
    const url = 'https://api.coingecko.com/api/v3/simple/price?ids=bitcoin&vs_currencies=usd';
    const headers = {};
    if (process.env.COINGECKO_API_KEY) {
      headers['x-cg-demo-api-key'] = process.env.COINGECKO_API_KEY;
    }
    
    const response = await fetch(url, { headers });
    if (!response.ok) throw new Error(`HTTP ${response.status}`);
    
    const data = await response.json();
    const price = data?.bitcoin?.usd;
    if (!price) throw new Error('No price in response');
    
    insertPrice('BTC', price, Date.now(), 'coingecko');
    console.log(`‚úÖ BTC: $${price.toLocaleString()}`);
  } catch (error) {
    console.error('‚ùå Price poll failed:', error.message);
  }
}
```

Wire it up in `server.js`:
```javascript
import { startPricePolling } from "./app/services/pricePoller.js";
// ...
startPricePolling(); // Add after other pollers
```

#### Day 4-5: Verify Data Quality

Check that you have sufficient, clean data:
```javascript
// Run verification
node -e "
import {initDb} from './db.js';
import {getPriceCount} from './app/db/pricesDb.js';
initDb();
const count = getPriceCount('BTC');
console.log('Total BTC prices:', count);
if (count < 8000) {
  console.error('‚ö†Ô∏è  Insufficient data for training!');
  process.exit(1);
}
console.log('‚úÖ Ready for model training');
"
```

---

### Week 2: Build & Train Model

#### Day 1: Install TensorFlow.js

```bash
cd backend
npm install @tensorflow/tfjs-node --save
```

#### Day 2-3: Feature Engineering

**File:** `backend/app/services/featureStore.js`

```javascript
import { getHistory } from '../db/pricesDb.js';
import { getHashrateHistory } from '../db/hashrateDb.js';
import { getDifficultyHistory } from '../db/difficultyDb.js';

export class FeatureStore {
  constructor() {
    this.stats = null;
  }
  
  // Compute features for a single timestamp
  computeFeatures(timestamp, lookback = 60) {
    const from = timestamp - lookback * 3600 * 1000;
    const prices = getHistory('BTC', from, timestamp, 1000);
    
    if (prices.length < lookback) {
      throw new Error(`Insufficient price data: ${prices.length} < ${lookback}`);
    }
    
    const features = [];
    
    for (let i = 0; i < lookback; i++) {
      const featureVec = {
        // Price features (5)
        log_return_1h: this.logReturn(prices, i, 1),
        log_return_24h: this.logReturn(prices, i, 24),
        sma_24h: this.sma(prices, i, 24),
        volatility_24h: this.volatility(prices, i, 24),
        rsi_14: this.rsi(prices, i, 14),
        
        // On-chain features (2) - simplified
        hashrate_normalized: 0.5, // Will implement after basic model works
        difficulty_normalized: 0.5,
        
        // Temporal features (2)
        hour_sin: Math.sin(2 * Math.PI * new Date(prices[i].ts).getHours() / 24),
        day_cos: Math.cos(2 * Math.PI * new Date(prices[i].ts).getDay() / 7)
      };
      
      features.push(featureVec);
    }
    
    return features;
  }
  
  logReturn(prices, idx, periods) {
    if (idx < periods || !prices[idx] || !prices[idx - periods]) return 0;
    return Math.log(prices[idx].price / prices[idx - periods].price);
  }
  
  sma(prices, idx, window) {
    if (idx < window - 1) return prices[idx].price;
    let sum = 0;
    for (let i = idx - window + 1; i <= idx; i++) {
      sum += prices[i].price;
    }
    return sum / window;
  }
  
  volatility(prices, idx, window) {
    if (idx < window) return 0;
    const slice = prices.slice(idx - window, idx + 1);
    const mean = slice.reduce((s, p) => s + p.price, 0) / slice.length;
    const variance = slice.reduce((s, p) => s + Math.pow(p.price - mean, 2), 0) / slice.length;
    return Math.sqrt(variance);
  }
  
  rsi(prices, idx, period = 14) {
    if (idx < period) return 50; // neutral
    
    let gains = 0, losses = 0;
    for (let i = idx - period + 1; i <= idx; i++) {
      const change = prices[i].price - prices[i - 1].price;
      if (change > 0) gains += change;
      else losses -= change;
    }
    
    const avgGain = gains / period;
    const avgLoss = losses / period;
    if (avgLoss === 0) return 100;
    
    const rs = avgGain / avgLoss;
    return 100 - (100 / (1 + rs));
  }
  
  // Compute normalization stats from all data
  computeStats(allPrices) {
    // Extract all features first
    const allFeatures = [];
    for (let i = 60; i < allPrices.length - 1; i++) {
      try {
        const feats = this.computeFeatures(allPrices[i].ts, 60);
        allFeatures.push(...feats);
      } catch (e) {
        // Skip if insufficient data
      }
    }
    
    // Compute min/max for each feature
    this.stats = {
      log_return_1h: { min: -0.1, max: 0.1 },
      log_return_24h: { min: -0.3, max: 0.3 },
      sma_24h: { min: 80000, max: 120000 },
      volatility_24h: { min: 0, max: 10000 },
      rsi_14: { min: 0, max: 100 },
      hashrate_normalized: { min: 0, max: 1 },
      difficulty_normalized: { min: 0, max: 1 },
      hour_sin: { min: -1, max: 1 },
      day_cos: { min: -1, max: 1 }
    };
    
    console.log('‚úÖ Feature stats computed');
  }
  
  normalize(features) {
    return features.map(feat => {
      const normalized = {};
      for (const [key, value] of Object.entries(feat)) {
        const stat = this.stats[key];
        normalized[key] = (value - stat.min) / (stat.max - stat.min + 1e-8);
      }
      return Object.values(normalized); // Return as array
    });
  }
}
```

#### Day 4-5: Training Script

**File:** `backend/scripts/train-model.js`

```javascript
import * as tf from '@tensorflow/tfjs-node';
import { initDb } from '../db.js';
import { getHistory } from '../app/db/pricesDb.js';
import { FeatureStore } from '../app/services/featureStore.js';

async function main() {
  initDb();
  
  console.log('üß† Building training dataset...');
  
  // Get all historical prices
  const now = Date.now();
  const twoYearsAgo = now - 730 * 24 * 60 * 60 * 1000;
  const allPrices = getHistory('BTC', twoYearsAgo, now, 20000);
  
  console.log(`   Loaded ${allPrices.length} price records`);
  
  if (allPrices.length < 1000) {
    throw new Error('Insufficient data! Run backfill-prices.js first');
  }
  
  const featureStore = new FeatureStore();
  featureStore.computeStats(allPrices);
  
  // Build dataset
  const dataset = [];
  for (let i = 60; i < allPrices.length - 1; i++) {
    try {
      const features = featureStore.computeFeatures(allPrices[i].ts, 60);
      const normalizedFeatures = featureStore.normalize(features);
      const target = allPrices[i + 1].price; // Predict next hour
      
      dataset.push({ features: normalizedFeatures, target });
    } catch (e) {
      // Skip samples with insufficient data
    }
  }
  
  console.log(`   Built dataset with ${dataset.length} samples`);
  
  // Train/val/test split
  const trainSize = Math.floor(dataset.length * 0.7);
  const valSize = Math.floor(dataset.length * 0.15);
  
  const trainData = dataset.slice(0, trainSize);
  const valData = dataset.slice(trainSize, trainSize + valSize);
  const testData = dataset.slice(trainSize + valSize);
  
  console.log(`   Train: ${trainData.length}, Val: ${valData.length}, Test: ${testData.length}`);
  
  // Convert to tensors
  const trainX = tf.tensor3d(trainData.map(d => d.features));
  const trainY = tf.tensor2d(trainData.map(d => [d.target]));
  const valX = tf.tensor3d(valData.map(d => d.features));
  const valY = tf.tensor2d(valData.map(d => [d.target]));
  
  console.log('üèóÔ∏è  Building LSTM model...');
  
  // Simple LSTM model
  const model = tf.sequential({
    layers: [
      tf.layers.lstm({ 
        units: 50, 
        returnSequences: true, 
        inputShape: [60, 9] // 60 timesteps, 9 features
      }),
      tf.layers.dropout({ rate: 0.2 }),
      tf.layers.lstm({ 
        units: 25, 
        returnSequences: false 
      }),
      tf.layers.dropout({ rate: 0.2 }),
      tf.layers.dense({ units: 1 })
    ]
  });
  
  model.compile({
    optimizer: tf.train.adam(0.001),
    loss: 'meanSquaredError',
    metrics: ['mae']
  });
  
  console.log('üéØ Training model...');
  
  const history = await model.fit(trainX, trainY, {
    epochs: 50,
    batchSize: 32,
    validationData: [valX, valY],
    callbacks: {
      onEpochEnd: (epoch, logs) => {
        console.log(`   Epoch ${epoch + 1}/50: loss=${logs.loss.toFixed(2)}, val_loss=${logs.val_loss.toFixed(2)}, mae=${logs.mae.toFixed(2)}`);
      }
    }
  });
  
  // Evaluate on test set
  const testX = tf.tensor3d(testData.map(d => d.features));
  const testY = tf.tensor2d(testData.map(d => [d.target]));
  const evalResult = model.evaluate(testX, testY);
  const testMAE = evalResult[1].dataSync()[0];
  
  console.log(`‚úÖ Test MAE: $${testMAE.toFixed(2)}`);
  console.log(`   (${(testMAE / 91000 * 100).toFixed(2)}% error)`);
  
  // Save model
  await model.save('file://./models/lstm-btc-1h');
  console.log('üíæ Model saved to ./models/lstm-btc-1h');
  
  // Cleanup
  tf.dispose([trainX, trainY, valX, valY, testX, testY]);
}

main().catch(console.error);
```

**Run training:**
```bash
cd backend
node scripts/train-model.js
```

Expected output:
- Training time: 5-15 minutes
- Target MAE: < $3,000 (< 3.3% error)

---

### Week 3: Deploy & Monitor

#### Day 1-2: Prediction Service

**File:** `backend/app/services/aiPredictionService.js`

```javascript
import * as tf from '@tensorflow/tfjs-node';
import { FeatureStore } from './featureStore.js';

export class AIPredictionService {
  constructor() {
    this.model = null;
    this.featureStore = new FeatureStore();
    this.initialized = false;
  }
  
  async initialize() {
    if (this.initialized) return;
    
    console.log('ü§ñ Loading LSTM model...');
    this.model = await tf.loadLayersModel('file://./models/lstm-btc-1h/model.json');
    
    // Load normalization stats (would need to save/load these properly)
    this.featureStore.computeStats([]); // Simplified for now
    
    this.initialized = true;
    console.log('‚úÖ AI prediction service ready');
  }
  
  async predictPrice() {
    if (!this.initialized) await this.initialize();
    
    const now = Date.now();
    const features = this.featureStore.computeFeatures(now, 60);
    const normalizedFeatures = this.featureStore.normalize(features);
    
    const inputTensor = tf.tensor3d([normalizedFeatures]);
    const predictionTensor = this.model.predict(inputTensor);
    const predictedPrice = predictionTensor.dataSync()[0];
    
    tf.dispose([inputTensor, predictionTensor]);
    
    return {
      model_id: 'lstm_btc_1h_v1',
      predicted_price: predictedPrice,
      confidence: 0.75, // Can improve this later
      horizon: '1h',
      timestamp: now
    };
  }
}
```

#### Day 3: Wire Up to Server

Add to `server.js`:
```javascript
import { AIPredictionService } from './app/services/aiPredictionService.js';
import { insertPrediction } from './app/db/predictionsDb.js';

const aiService = new AIPredictionService();

// Initialize on startup
aiService.initialize().catch(console.error);

// Generate predictions hourly
setInterval(async () => {
  try {
    const pred = await aiService.predictPrice();
    insertPrediction(pred.model_id, 'BTC', pred.predicted_price, pred.confidence, pred.horizon);
    console.log(`üîÆ AI Prediction: $${pred.predicted_price.toFixed(2)}`);
  } catch (error) {
    console.error('Prediction failed:', error.message);
  }
}, 60 * 60 * 1000); // Every hour
```

#### Day 4-5: API Endpoints & Testing

Add route:
```javascript
// GET /api/ai/predictions/latest
router.get('/ai/predictions/latest', async (req, res) => {
  try {
    const prediction = await aiService.predictPrice();
    const currentPrice = getLatestPrice('BTC');
    
    res.json({
      current_price: currentPrice.price,
      predicted_price_1h: prediction.predicted_price,
      confidence: prediction.confidence,
      timestamp: prediction.timestamp
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
```

---

## üìã IMMEDIATE ACTION STEPS

### Step 1: Backfill Data (TODAY)
```bash
cd /home/omar/WIP/backend
node scripts/backfill-prices.js BTC 730
```

### Step 2: Verify Data (TODAY)
```bash
node -e "
import {initDb} from './db.js';
import {getPriceCount} from './app/db/pricesDb.js';
initDb();
console.log('BTC prices:', getPriceCount('BTC'));
"
```

Should show: **17,500+** rows

### Step 3: Install TensorFlow.js (TOMORROW)
```bash
npm install @tensorflow/tfjs-node --save
```

### Step 4: Create Files (NEXT 3 DAYS)
1. `app/services/pricePoller.js`
2. `app/services/featureStore.js`
3. `scripts/train-model.js`

### Step 5: Train Model (DAY 5-6)
```bash
node scripts/train-model.js
```

### Step 6: Deploy (WEEK 3)
1. Create `aiPredictionService.js`
2. Wire up to server
3. Test predictions
4. Monitor accuracy

---

## ‚úÖ SUCCESS CRITERIA

- [ ] Database has 15,000+ BTC price records
- [ ] Model trains successfully (MAE < $3,000)
- [ ] Live predictions every hour
- [ ] API returns predictions with confidence
- [ ] Predictions are realistic ($88k - $95k range currently)
- [ ] System runs without crashes for 24 hours

---

## üö® CRITICAL NOTES

1. **Current BTC Price: ~$91,195** - Model must predict in realistic range
2. **Your data is GOOD** - 74 real records, just need more volume
3. **No database path issues** - Everything uses `data/prices.sqlite` correctly
4. **Backfill script works** - Tested and confirmed
5. **Start with simple model** - Can improve later

---

**Status:** ‚úÖ Ready to start with Step 1 (backfill data)

**Next Action:** Run `node scripts/backfill-prices.js BTC 730` NOW
